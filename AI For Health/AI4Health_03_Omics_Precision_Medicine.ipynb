{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29421cb",
   "metadata": {},
   "source": [
    "# AI4Health - 03 – Omics: Precision Medicine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827cea3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ad3c1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Modern medicine is increasingly driven by **omics data**, a large-scale measurements of genes, transcripts, proteins, and more. In diseases like acute myeloid leukemia (AML), analysing thousands of gene expression levels per patient has revealed hidden subtypes that respond differently to treatment. This ability to discover new patient groups is a cornerstone of **precision medicine**, where therapies are tailored to the unique biology of each individual.\n",
    "\n",
    "In this notebook, you will use unsupervised machine learning to explore gene expression data from leukemia patients. By applying dimensionality reduction and clustering techniques, you will uncover patterns that may correspond to clinically meaningful subgroups—potentially leading to more personalised care.\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "- Understand the structure and challenges of gene expression (omics) datasets\n",
    "- Apply **Principal Component Analysis (PCA)** to reduce dimensionality and reveal major biological signals\n",
    "- Use **K-Means clustering** to identify potential patient subtypes\n",
    "- Visualise and interpret the results in the context of precision medicine\n",
    "\n",
    "By the end of this notebook, you will have hands-on experience with the core steps of omics data analysis, and a deeper appreciation for how machine learning can drive discoveries in personalised healthcare.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "- Recognise the challenges of high-dimensional omics data\n",
    "- Apply PCA for dimensionality reduction in gene expression analysis\n",
    "- Use clustering to identify potential disease subtypes\n",
    "- Reflect on the clinical impact of data-driven patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84472d86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d173ad",
   "metadata": {},
   "source": [
    "## Additional Context\n",
    "\n",
    "### What is Omics Data?\n",
    "\n",
    "Omics data refers to large-scale biological measurements that capture the molecular makeup of cells, tissues, or organisms. Common omics types include:\n",
    "- **Genomics** (DNA sequences and mutations)\n",
    "- **Transcriptomics** (gene expression levels)\n",
    "- **Proteomics** (protein abundance)\n",
    "- **Metabolomics** (small molecule metabolites)\n",
    "\n",
    "In clinical research, omics data is often represented as a matrix where each row is a patient (or sample) and each column is a molecular feature (e.g., gene or protein). These datasets are typically **high-dimensional**—with thousands of features but relatively few samples.\n",
    "\n",
    "### Gene‑expression matrices & the need for dimensionality reduction\n",
    "A typical gene‑expression experiment measures **>10 000 genes** for **only a few dozen patients**:\n",
    "\n",
    "| patients (rows) | genes (columns) |\n",
    "|-----------------|-----------------|\n",
    "| 72              | 7 129           |\n",
    "\n",
    "That many columns cause:\n",
    "* **Curse of dimensionality** – Euclidean distances become less meaningful, hurting clustering.\n",
    "* **Over‑fitting** – more features than samples means many spurious patterns.\n",
    "* **Computation & memory** – every extra dimension costs RAM & CPU.\n",
    "\n",
    "### Principal Component Analysis (PCA) in this context\n",
    "PCA rotates the data into a new set of orthogonal axes (principal components, PCs) ordered by how much variance they capture.  In gene‑expression:\n",
    "1. **Center & scale** each gene (z‑score).\n",
    "2. Compute covariance matrix of genes.\n",
    "3. Eigen‑decompose to get PCs.\n",
    "4. Keep the top *k* PCs that explain most variance (often 2‑50), giving a *compressed* representation while preserving the major biological signals.\n",
    "\n",
    "### Why Use Clustering in Precision Medicine?\n",
    "\n",
    "Clustering algorithms like **K-Means** group patients based on molecular similarity, without using predefined labels. This can reveal:\n",
    "- **Hidden subtypes** of disease that may respond differently to treatment\n",
    "- **Patient stratification** for personalised therapies\n",
    "- **Biological insights** into disease mechanisms\n",
    "\n",
    "Unsupervised clustering is a key step in **precision medicine**, where the goal is to tailor treatments to the unique molecular profile of each patient.\n",
    "\n",
    "### Key Concepts in Omics Machine Learning\n",
    "\n",
    "When applying machine learning to omics data, several foundational concepts are essential for meaningful analysis and interpretation. These concepts help address the unique challenges posed by high-dimensional biological datasets and ensure that results are robust and biologically relevant.\n",
    "\n",
    "- **Normalisation**: Ensures each gene or feature contributes equally by removing scale differences.\n",
    "- **Principal Components**: New axes that summarise the main sources of variation in the data.\n",
    "- **Cluster Validation**: Assessing whether discovered groups are biologically or clinically meaningful.\n",
    "- **Visualisation**: Essential for interpreting patterns and communicating findings in high-dimensional data.\n",
    "\n",
    "### Clinical and Ethical Considerations\n",
    "\n",
    "When working with omics data, it is essential to address clinical and ethical issues alongside technical analysis. Responsible machine learning in precision medicine demands that models are interpretable and validated with independent data and clinical outcomes. Protecting patient privacy is paramount, and care must be taken to ensure findings are generalisable and do not worsen health disparities, so that advances translate into real-world benefits without unintended harm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b9303",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262bf1b",
   "metadata": {},
   "source": [
    "## Related Guides\n",
    "\n",
    "- *MatPlotLib - Pyplot:* https://matplotlib.org/stable/tutorials/pyplot.html\n",
    "- *Seaborn - Kernel density estimation:* https://seaborn.pydata.org/tutorial/distributions.html#tutorial-kde\n",
    "- *SciKit-Learn - Downloading datasets from openml.org:* https://scikit-learn.org/stable/datasets/loading_other_datasets.html#openml\n",
    "- *SciKit-Learn - Generated datasets (blobs):* https://scikit-learn.org/stable/datasets/sample_generators.html\n",
    "- *SciKit-Learn - K-means:* https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "- *SciKit-Learn - Preprocessing data (standard scaler):* https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- *SciKit-Learn - Principal component analysis (PCA):* https://scikit-learn.org/stable/modules/decomposition.html#pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d110d35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76631c8",
   "metadata": {},
   "source": [
    "## Step 1: Load Required Libraries\n",
    "\n",
    "Before starting the analysis, we need to import essential Python libraries. These include tools for data manipulation (NumPy), preprocessing and scaling, dimensionality reduction (PCA), clustering (KMeans), and visualisation (matplotlib). Loading these libraries allows us to handle large datasets and exploring high-dimensional gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb80aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml, make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Matplotlib settings for crisp plots\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd2c40",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **1.1.** Why do we need specialised libraries for analysing high-dimensional omics data?\n",
    "- **1.2.** What is the role of dimensionality reduction (like PCA) in gene expression analysis?\n",
    "- **1.3.** How do clustering algorithms such as K-Means contribute to precision medicine?\n",
    "- **1.4.** Why is visualisation important when working with thousands of features?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89873cf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e563dda0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b1a53",
   "metadata": {},
   "source": [
    "## Step 2: Load gene‑expression data\n",
    "\n",
    "Gene expression datasets typically consist of thousands of genes measured across a relatively small number of patients. In this step, we’ll load such a dataset, ideally a real-world leukemia dataset, but we’ll generate synthetic data if needed. We’ll examine the shape and structure of the data, which is crucial for understanding the challenges of high-dimensional analysis. Previewing the data helps us verify that it loaded correctly and gives us a sense of what each row (patient) and column (gene) represents, setting the stage for meaningful downstream analysis.\n",
    "\n",
    "- *SciKit-Learn - fetch_openml:* https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html\n",
    "- *SciKit-Leanr - make_blobs:* https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We try to fetch the classic Golub leukemia dataset via OpenML (ID 1104).\n",
    "# If internet is unavailable, we fall back to a tiny synthetic set so the notebook\n",
    "# always runs on limited hardware.\n",
    "try:\n",
    "    leukemia = fetch_openml(data_id=1104, as_frame=False)  # 7 129 genes × 72 patients\n",
    "    X = leukemia.data\n",
    "    y = leukemia.target.astype(str)  # 'ALL' vs 'AML'\n",
    "    print(f\"Leukemia matrix shape: {X.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"OpenML download failed - generating synthetic data.\")\n",
    "    X, y = make_blobs(n_samples=120, n_features=500, centers=3, random_state=42)\n",
    "    y = y.astype(str)\n",
    "    print(f\"Synthetic matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfe53a",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **2.1.** Why are gene expression datasets typically so high-dimensional, and what challenges does this create for analysis?\n",
    "- **2.2.** What are the differences between real and synthetic gene expression data, and how might this affect your results?\n",
    "- **2.3.** Why is it important to know the biological meaning of your samples and features before proceeding?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24fecd30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21336914",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8640e0",
   "metadata": {},
   "source": [
    "## Step 3: Normalise (z‑score)\n",
    "\n",
    "Raw gene expression values can vary greatly in scale, both across genes and between patients. To ensure that each gene contributes equally to our analysis, we standardise the data by centering each gene to have a mean of 0 and scaling to unit variance (z-scoring). This normalisation step is critical before applying PCA or clustering, as it prevents highly expressed genes from dominating the results and ensures that all features are on a comparable scale. We will check the mean and standard deviation after scaling to confirm that the normalisation was successful.\n",
    "\n",
    "- *SciKit-Learn - StandardScaler:* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each gene is centred to mean 0 and scaled to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # shape unchanged\n",
    "print(f\"Scaled matrix mean = {X_scaled.mean():.3f}, std = {X_scaled.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe47de3",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **3.1.** Why is normalisation (z-scoring) necessary for gene expression data before PCA or clustering?\n",
    "- **3.2.** What could happen if you skip normalisation when analysing omics data?\n",
    "- **3.3.** How does scaling each gene to mean 0 and variance 1 affect the interpretation of downstream results?\n",
    "- **3.4.** Are there situations where a different normalisation method might be more appropriate?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab41a6a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d79be7e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f8025",
   "metadata": {},
   "source": [
    "## Step 4: Visualise Normalised Data\n",
    "\n",
    "Before proceeding to PCA, it is helpful to visualise the normalised data to ensure that the scaling process was successful. This step includes plotting a heatmap of the normalised gene expression matrix and visualising the distribution of a few selected genes.\n",
    "\n",
    "Visualisation helps confirm that the data is properly scaled and ready for dimensionality reduction.\n",
    "\n",
    "- *Seaborn - heatmap:* https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "- *Seaborn - kdeplot:* https://seaborn.pydata.org/generated/seaborn.kdeplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heatmap of a subset of the normalised data\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(X_scaled[:10, :50], cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Heatmap of Normalised Gene Expression (Subset)\")\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Patients\")\n",
    "plt.show()\n",
    "\n",
    "# Visualise the distribution of a few selected genes\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(3):  # Plot distributions for 3 random genes\n",
    "    sns.kdeplot(X_scaled[:, i], label=f\"Gene {i+1}\")\n",
    "plt.title(\"Distribution of Selected Normalised Genes\")\n",
    "plt.xlabel(\"Z-Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe5681",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **4.1.** What insights can you gain from the heatmap of the normalised gene expression data?\n",
    "- **4.2.** Why is it important to visualise the distribution of selected genes after normalisation?\n",
    "- **4.3.** How might anomalies in the visualisation indicate issues with the normalisation process?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bda7be43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9831225f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d78097",
   "metadata": {},
   "source": [
    "## Step 5: Principal Component Analysis (PCA)\n",
    "\n",
    "With normalised data, we can now apply Principal Component Analysis (PCA) to reduce the dataset’s dimensionality. PCA transforms the data into a new set of orthogonal axes (principal components) that capture the greatest variance. By projecting the data onto the top principal components, we retain the most important biological signals while discarding noise and redundancy. This step makes the data easier to visualise and interpret, and prepares it for clustering. We will plot the first two principal components to visually explore patterns and potential groupings among patients.\n",
    "\n",
    "- *SciKit-Learn - PCA:* https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain just enough PCs to explain 90 % variance\n",
    "pca = PCA(n_components=0.90, svd_solver='full', random_state=0)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Reduced to {X_pca.shape[1]} PCs covering {pca.explained_variance_ratio_.sum():.2%} variance\")\n",
    "\n",
    "# Plot first 2 PCs\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=20, alpha=0.7)\n",
    "plt.title(\"PCA - first two components\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcb8d2",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **5.1.** Do you notice distinct groups or gradients, and what might separate those samples biologically?\n",
    "- **5.2.** How do you decide how many principal components to retain?\n",
    "- **5.3.** What does it mean if you see clear groupings or gradients in the first two PCs?\n",
    "- **5.4.** What are the limitations of PCA for exploring biological data?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72797ced",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e586d14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db247db0",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate PCA Results\n",
    "\n",
    "After performing PCA, it is important to evaluate the explained variance ratio for each principal component. This step includes plotting a scree plot to show how much variance is captured by each component and deciding the optimal number of components to retain.\n",
    "\n",
    "The scree plot helps identify the \"elbow point,\" where additional components contribute less to the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance ratio for each principal component\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='orange')\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Variance Explained\")\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label=\"90% Variance\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e6356",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **6.1.** What does the \"elbow point\" in the scree plot represent, and how does it guide the selection of principal components?\n",
    "- **6.2.** Why is it important to consider cumulative explained variance when deciding the number of components to retain?\n",
    "- **6.3.** How might retaining too few or too many principal components affect the downstream clustering results?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7ea8dae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27955dce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806dba5",
   "metadata": {},
   "source": [
    "## Step 7: K‑Means Clustering on PCA Space\n",
    "\n",
    "After reducing the data’s dimensionality, we use K-Means clustering to group patients based on their gene expression profiles in the PCA-transformed space. Clustering helps us identify potential subtypes or patterns that may correspond to clinically meaningful groups. By visualising the clusters on the first two principal components, we can assess whether distinct groups emerge and consider their possible biological or clinical significance. This step demonstrates how unsupervised learning can generate hypotheses about disease subtypes and inform precision medicine.\n",
    "\n",
    "- *SciKit-Learn - KMeans:* https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4765903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster in the reduced space (keep k small for resource limits)\n",
    "k = 3\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "print(\"Cluster sizes:\", numpy.bincount(labels))\n",
    "\n",
    "# Visualise clusters\n",
    "plt.figure()\n",
    "for lab in range(k):\n",
    "    plt.scatter(X_pca[labels==lab, 0], X_pca[labels==lab, 1], label=f\"Cluster {lab}\", s=20, alpha=0.7)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"K-Means clusters on PCA projection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01e7fe",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **7.1.** What does this cluster composition suggest?\n",
    "- **7.2.** What clinical decisions might hinge on distinguishing these clusters?\n",
    "- **7.3.** How do you choose the number of clusters (k) in K-Means, and what are the risks of choosing too many or too few?\n",
    "- **7.4.** What does it mean if clusters align (or do not align) with known clinical subtypes?\n",
    "- **7.5.** How could clustering results inform clinical decisions or future research in precision medicine?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a9644d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d0ea14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3006a9a",
   "metadata": {},
   "source": [
    "## Step 8: Summary and Reflection\n",
    "\n",
    "In this notebook, you explored the application of unsupervised machine learning to high-dimensional gene expression (omics) data—a cornerstone of modern precision medicine. Starting with the challenges of analysing thousands of genes across a small number of patients, you learned how dimensionality reduction (PCA) can reveal major biological patterns and make complex data more interpretable. Clustering in the reduced PCA space allowed you to identify potential patient subtypes, which may correspond to clinically meaningful groups and inform more personalised treatment strategies.\n",
    "\n",
    "Throughout the workflow, you saw the importance of careful data preprocessing (such as normalisation), the power of visualisation for understanding hidden structure, and the limitations of unsupervised methods in biological discovery. You also reflected on how these computational techniques can drive advances in personalised healthcare, while recognising the need for biological validation and clinical context.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Omics datasets are high-dimensional and require dimensionality reduction for effective analysis.\n",
    "- PCA helps uncover major biological signals and prepares data for clustering.\n",
    "- K-Means clustering in PCA space can reveal potential disease subtypes.\n",
    "- Visualisation is key to interpreting complex patterns in gene expression data.\n",
    "- Unsupervised methods can generate hypotheses for precision medicine, but require clinical validation.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "- **8.1.** How could you validate whether discovered clusters correspond to real clinical subtypes?\n",
    "- **8.2.** What additional data (e.g., clinical outcomes, genetic mutations) could help interpret the clusters?\n",
    "- **8.3.** How might these methods be extended to multi-omics or longitudinal data?\n",
    "- **8.4.** What are the ethical and practical considerations when using unsupervised learning to guide clinical decisions?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef53e89a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c6f2e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815379c",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "### Articles\n",
    "\n",
    "- **Unsupervised machine learning for exploratory data analysis in imaging mass spectrometry**\n",
    "<br>*Mass Spectrometry Reviews*\n",
    "  - https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/10.1002/mas.21602\n",
    "\n",
    "- **Dimension reduction techniques for the integrative analysis of multi-omics data**\n",
    "<br>*Briefings in Bioinformatics*\n",
    "  - https://academic.oup.com/bib/article/17/4/628/2240645\n",
    "\n",
    "- **Clustering and visualization of single-cell RNA-seq data using path metrics**\n",
    "<br>*PLOS Computational Biology*\n",
    "  - https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009473a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
