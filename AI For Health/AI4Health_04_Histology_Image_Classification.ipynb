{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddd6895",
   "metadata": {},
   "source": [
    "# AI4Health - 04 – Histology Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe0a79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac1429",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Histopathology is the study of microscopic images of tissue, and it plays a crucial role in diagnosing diseases like cancer. Pathologists examine stained tissue samples under a microscope to look for abnormal cells. This process, while highly effective, is also time-consuming and requires years of expertise. With the growing number of cases and a shortage of specialists, there is a strong need for computational tools that can assist in diagnosis.\n",
    "\n",
    "In this notebook, you will learn how to use machine learning to classify small patches of histology images as either cancerous or non-cancerous. Instead of using advanced deep learning models (like Convolutional Neural Networks), we will start with a simple approach: flattening each image into a 1D array of pixel values and using a **Logistic Regression** model. This method is easy to understand and implement, making it a great starting point for those new to medical image analysis.\n",
    "\n",
    "You will learn how to:\n",
    "- Prepare image data for machine learning\n",
    "- Train and evaluate a simple classification model\n",
    "- Interpret model results and identify challenges in medical image classification\n",
    "\n",
    "By the end of this notebook, you’ll have hands-on experience with a real-world medical dataset and a better understanding of how machine learning can support healthcare professionals.\n",
    "\n",
    "### Learning Objectives:\n",
    "- Understand the basics of histopathology images and their role in medical diagnosis.\n",
    "- Learn how to load, preprocess, and visualise medical image data in Python.\n",
    "- Apply logistic regression to classify image patches as cancerous or non-cancerous.\n",
    "- Evaluate model performance and interpret classification results.\n",
    "- Reflect on the challenges and limitations of classical machine learning for medical images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b4470",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77040cd",
   "metadata": {},
   "source": [
    "## Additional Context\n",
    "\n",
    "### What Are Histology Images?\n",
    "\n",
    "Histology images are high-resolution scans of stained tissue samples. Staining (e.g., Hematoxylin and Eosin) highlights cellular structures to help pathologists detect abnormalities. In digital pathology, these images are divided into smaller **patches** for analysis.\n",
    "\n",
    "We will use the **IDC Breast Histopathology dataset** which contains 50x50 patches labeled as either:\n",
    "- `0`: Non-invasive (normal)\n",
    "- `1`: Invasive Ductal Carcinoma (IDC)\n",
    "\n",
    "### Why Use Classical Machine Learning Instead of Deep Learning?\n",
    "\n",
    "While modern deep learning models (such as Convolutional Neural Networks, CNNs) excel at image classification, they require large datasets and significant computational resources. As a baseline, this notebook uses a simpler approach:\n",
    "- **Flattening** each image into a 1D array of pixel values\n",
    "- **Normalising** pixel values to a standard range (0–1)\n",
    "- Training a **Logistic Regression** model\n",
    "\n",
    "This classical approach is accessible, interpretable, and suitable for small datasets or limited hardware, helping you focus on the core machine learning workflow.\n",
    "\n",
    "### Key Concepts in Medical Image Analysis\n",
    "\n",
    "Understanding the foundational concepts in medical image analysis is essential for building effective and trustworthy machine learning models. These concepts guide how we prepare, represent, and interpret image data, especially when working with sensitive clinical information. Below are some of the most important considerations:\n",
    "\n",
    "- **Preprocessing**: Standardising image size, color channels (e.g., converting to grayscale), and normalisation are crucial for consistent analysis.\n",
    "- **Feature Representation**: Flattening images allows classical models to process them, but may lose spatial information compared to CNNs.\n",
    "- **Class Imbalance**: Medical datasets often have more normal than abnormal samples, which can bias models if not addressed.\n",
    "- **Interpretability**: Simple models like logistic regression are easier to interpret, which is important for clinical trust and adoption.\n",
    "\n",
    "### Challenges in Medical Image Classification\n",
    "\n",
    "Medical image classification presents unique challenges that stem from both the complexity of biological tissues and the technical aspects of image acquisition. Recognising these challenges helps in designing robust models and understanding their limitations:\n",
    "\n",
    "- **Subtle Differences**: Cancerous and non-cancerous tissue may look very similar, especially in small patches.\n",
    "- **Image Artifacts**: Variability in staining, scanning, or tissue preparation can introduce noise.\n",
    "- **Data Volume**: Large whole-slide images are often split into thousands of patches, creating challenges for storage and computation.\n",
    "- **Label Quality**: Accurate labeling requires expert pathologists, and errors can impact model performance.\n",
    "\n",
    "### Clinical and Ethical Considerations\n",
    "\n",
    "Applying machine learning to medical images requires careful attention to clinical and ethical issues to ensure models are safe, fair, and trustworthy. Clinicians must be able to understand and trust predictions, so transparency is essential. Rigorous validation on independent data is needed before clinical use. Datasets should represent diverse populations to prevent bias, and sensitive medical images must be handled securely to protect privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb7878",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841dbdd",
   "metadata": {},
   "source": [
    "## Related Guides\n",
    "\n",
    "- *MatPlotLib - Pyplot:* https://matplotlib.org/stable/tutorials/pyplot.html\n",
    "- *SciKit-Learn - Confusion Matrix:* https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix\n",
    "- *SciKit-Learn - Cross Validation (train, test, split):* https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "- *SciKit-Learn - Tuning the hyperparameters (grid search):* https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- *SciKit-Learn - Logistic Regression:* https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1aea02",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882df81",
   "metadata": {},
   "source": [
    "## Step 1: Load Required Libraries\n",
    "\n",
    "To begin our analysis, we import the essential Python libraries for image processing, visualisation, and machine learning. These include tools for handling file paths, manipulating arrays, displaying images, and building classification models. Loading these libraries ensures we have everything needed to work with image data and apply machine learning techniques in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "from skimage.util import random_noise\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630877f9",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **1.1.** Why do we need specialised libraries for working with medical images?\n",
    "- **1.2.** What roles do libraries like PIL and matplotlib play in image analysis?\n",
    "- **1.3.** How does the choice of machine learning library affect the types of models you can build?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f85a24d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6567b25f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8102c856",
   "metadata": {},
   "source": [
    "## Step 2: Image Handling Tips: PIL and matplotlib\n",
    "\n",
    "This section provides practical guidance on working with medical images in Python. We demonstrate how to load, preprocess, and visualise images using the PIL and matplotlib libraries. These basic image handling techniques are essential for inspecting data, debugging preprocessing steps, and ensuring that images are correctly formatted for analysis. Mastery of these tools is a key skill for anyone working in medical image analysis.\n",
    "\n",
    "- *Pillow - Image:* https://pillow.readthedocs.io/en/latest/reference/Image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ada133",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"datasets/breast_histopathology_image_samples/8863/1/8863_idx5_x1001_y801_class1.png\").convert(\"L\")  # Load grayscale\n",
    "img = img.resize((50, 50))  # Resize\n",
    "arr = numpy.array(img) / 255.0  # Normalise\n",
    "\n",
    "plt.imshow(arr, cmap='gray')\n",
    "plt.title(\"Sample Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b2ff4",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **2.1.** How can visualisation help you debug preprocessing steps?\n",
    "- **2.2.** Why is it important to ensure consistent image formatting before analysis?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22b7bae6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56005584",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145146c8",
   "metadata": {},
   "source": [
    "## Step 3: Load the Dataset\n",
    "\n",
    "In this step, we load a sample of histology image patches from the dataset. Each image is labeled as either cancerous or non-cancerous. We read the image files from disk, resize them for consistency, convert them to grayscale to simplify the analysis, and flatten each image into a one-dimensional array of pixel values. This transformation prepares the images for use with classical machine learning models, which expect tabular input rather than raw image files. After loading, we combine the images and their labels into arrays for further processing and print out the dataset shape to confirm everything loaded as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f14af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small sample of images for demonstration\n",
    "def load_images(base_path, label, max_images=100):\n",
    "    images = []\n",
    "    labels = []\n",
    "    path = os.path.join(base_path, str(label))\n",
    "    files = os.listdir(path)\n",
    "    for fname in random.sample(files, min(len(files), max_images)):\n",
    "        img = Image.open(os.path.join(path, fname)).resize((50, 50)).convert('L')\n",
    "        images.append(numpy.array(img).flatten())\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Example path structure\n",
    "base_path = \"datasets/breast_histopathology_image_samples/8863/\"\n",
    "class0_imgs, class0_labels = load_images(base_path, label=0, max_images=1000)\n",
    "class1_imgs, class1_labels = load_images(base_path, label=1, max_images=1000)\n",
    "\n",
    "X = numpy.array(class0_imgs + class1_imgs)\n",
    "y = numpy.array(class0_labels + class1_labels)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Class distribution: {numpy.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8973b9",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **3.1.** Why do we convert images to grayscale and resize them before analysis?\n",
    "- **3.2.** What are the advantages and limitations of flattening images into 1D arrays for machine learning?\n",
    "- **3.3.** How can you verify that your dataset has been loaded and labeled correctly?\n",
    "- **3.4.** What challenges might arise when working with real-world medical image datasets?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cff1b13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825bcc83",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e330e",
   "metadata": {},
   "source": [
    "## Step 4: Visualising Sample Images\n",
    "\n",
    "Before training a model, it is important to visualise some of the image patches from the dataset. By displaying a grid of images along with their labels, we can better understand the kinds of patterns and features present in the data. This step helps us see what the model will be learning from and can reveal challenges such as subtle differences between classes or noisy samples. Visualisation also provides an opportunity to check that the data has been loaded and preprocessed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(n=8):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        # Randomly select an index for each class\n",
    "        index0 = random.randint(0, len(class0_imgs) - 1)\n",
    "        index1 = random.randint(0, len(class1_imgs) - 1)\n",
    "        # Select images from both classes\n",
    "        if i < n/2:\n",
    "            image = class0_imgs[index0]\n",
    "            label = class0_labels[index0]\n",
    "        else:\n",
    "            image = class1_imgs[index1]\n",
    "            label = class1_labels[index1]\n",
    "        # Plot the image\n",
    "        plt.subplot(2, n//2, i+1)\n",
    "        img = image.reshape(50, 50)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis(\"off\")\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_random_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd85e8f6",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **4.1.** What patterns or differences can you observe between cancerous and non-cancerous patches?\n",
    "- **4.2.** How might image quality or artifacts affect model performance?\n",
    "- **4.3.** What can visualisation reveal about potential data issues?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1702daee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ff3027",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e0bfd",
   "metadata": {},
   "source": [
    "## Step 5: Data Augmentation\n",
    "\n",
    "To improve the diversity of our dataset and help the model generalise better, we can apply basic data augmentation techniques. These include flipping, rotating, and adding noise to the images. Data augmentation is especially useful when working with small datasets, as it artificially increases the number of training samples.\n",
    "\n",
    "- *SciPy - rotate:* https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.rotate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    # Apply random rotation\n",
    "    rotated = rotate(image, angle=random.choice([90, 180, 270]), reshape=False)\n",
    "    # Add random noise\n",
    "    noisy = random_noise(rotated, mode='gaussian', var=0.01)\n",
    "    return noisy\n",
    "\n",
    "# Apply augmentation to a subset of images (e.g., first 10 images of class 0)\n",
    "augmented_images = [augment_image(img.reshape(50, 50)).flatten() for img in class0_imgs[:10]]\n",
    "augmented_labels = [0] * len(augmented_images)\n",
    "\n",
    "# Add augmented data to the dataset\n",
    "X = numpy.vstack([X, augmented_images])\n",
    "y = numpy.hstack([y, augmented_labels])\n",
    "\n",
    "print(f\"Augmented dataset shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece5463",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **5.1.** How does data augmentation improve model performance?\n",
    "- **5.2.** What are the risks of over-augmenting a dataset?\n",
    "- **5.3.** How can you ensure that augmented images still represent the original data distribution?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d8e9192",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c965ba3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23f5ad",
   "metadata": {},
   "source": [
    "## Step 6: Normalise, Split, and Train the Model\n",
    "\n",
    "With the data prepared, we proceed to normalise the pixel values so that they fall within a standard range, which helps the model train more effectively. We then split the dataset into training and testing sets to ensure that we can fairly evaluate the model’s performance on unseen data. Next, we train a logistic regression model using the flattened image data. After training, we generate predictions on the test set and assess the model’s performance using standard classification metrics and a confusion matrix. This step demonstrates how a simple, interpretable machine learning model can be applied to image classification tasks, even without deep learning.\n",
    "\n",
    "- *SciKit-Learn - ConfusionMatrixDisplay:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\n",
    "- *SciKit-Learn - LogisticRegression:* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- *SciKit-Learn - train_test_split:* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise and split\n",
    "X = X / 255.0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355e084",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **6.1.** Why do we normalise pixel values before training a machine learning model?\n",
    "- **6.2.** What are the strengths and limitations of using logistic regression for image classification?\n",
    "- **6.3.** How do you interpret the classification report and confusion matrix in a clinical context?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26b63807",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfd0000d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21d9bd",
   "metadata": {},
   "source": [
    "## Step 7: What’s Going Wrong?\n",
    "\n",
    "To gain deeper insight into the model’s limitations, we examine some of the images that were misclassified. By visualising these challenging cases, we can look for patterns or features that may have confused the model. This analysis helps us reflect on the difficulty of the task, especially when working with low-resolution images or subtle visual differences. Understanding where and why the model makes mistakes is crucial for improving future models and for interpreting results in a clinical context.\n",
    "\n",
    "- *Numpy - where:* https://numpy.org/doc/stable/reference/generated/numpy.where.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ca7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(X, y, n=8):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n//2, i+1)\n",
    "        img = X[i].reshape(50, 50)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Label: {y[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Identify misclassified images by comparing predictions with true labels\n",
    "misclassified = numpy.where(y_pred != y_test)[0]\n",
    "print(f\"Misclassified images found: {len(misclassified)}\")\n",
    "\n",
    "plot_sample_images(X_test[misclassified], y_test[misclassified])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b00eb3",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **7.1.** What patterns do you notice in the misclassified images?\n",
    "- **7.2.** How might low image resolution or subtle features contribute to misclassification?\n",
    "- **7.3.** Why is it important to analyse model errors in medical applications?\n",
    "- **7.4.** How could you address the limitations revealed by misclassified examples?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b5b4460",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f883a356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97959efc",
   "metadata": {},
   "source": [
    "## Step 8: Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is a critical step in optimising machine learning models. For logistic regression, we can adjust parameters such as the regularisation strength (`C`) and the solver type. This step demonstrates how to systematically search for the best combination of hyperparameters to improve model performance.\n",
    "\n",
    "- *SciKit-Learn - GridSearchCV:* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "- *SciKit-Learn - LogisticRegression:* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68952b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters and score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade696d",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **8.1.** Why is cross-validation important during hyperparameter tuning?\n",
    "- **8.2.** How do you decide which hyperparameters to tune?\n",
    "- **8.3.** What are the trade-offs between different solvers in logistic regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5ad6119",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "335519c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df151b",
   "metadata": {},
   "source": [
    "## Step 9: Feature Importance Analysis\n",
    "\n",
    "Understanding which features (pixels) contribute most to the model's predictions can provide valuable insights. For logistic regression, the model coefficients represent the importance of each feature. By visualising these coefficients, we can identify which regions of the image are most influential in distinguishing between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape coefficients to match image dimensions\n",
    "coefficients = model.coef_.reshape(50, 50)\n",
    "\n",
    "# Visualise feature importance\n",
    "plt.imshow(coefficients, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar(label=\"Feature Importance\")\n",
    "plt.title(\"Logistic Regression Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa03af8",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **9.1.** What do the most important features reveal about the dataset?\n",
    "- **9.2.** How can feature importance analysis help improve model performance?\n",
    "- **9.3.** What are the limitations of interpreting feature importance in logistic regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93cf133b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3bcb79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd19af",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Reflection\n",
    "\n",
    "In this notebook, you completed the full workflow of histology image classification using classical machine learning methods. You began by loading and preprocessing digital pathology images, converting them to grayscale and flattening them into feature vectors suitable for traditional models. By visualising sample images, you gained insight into the types of patterns present in the data and the challenges of distinguishing between cancerous and non-cancerous tissue.\n",
    "\n",
    "You then normalised the data, split it into training and testing sets, and trained a logistic regression classifier. Model performance was evaluated using standard metrics and confusion matrices, allowing you to identify both strengths and weaknesses in the predictions. By examining misclassified images, you reflected on the limitations of simple models when faced with subtle or complex visual differences.\n",
    "\n",
    "Throughout the process, you also practiced essential image handling techniques in Python, building a foundation for more advanced work in medical image analysis. This exercise highlighted the importance of careful data preparation, visualisation, and critical evaluation of results, especially in a clinical context where accuracy and interpretability are crucial.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Classical machine learning can be applied to medical image classification by flattening images into feature vectors.\n",
    "- Visualisation and normalisation are key steps in preparing image data for analysis.\n",
    "- Logistic regression provides a simple, interpretable baseline for image classification tasks.\n",
    "- Examining misclassified examples helps reveal model limitations and guides future improvements.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "- **10.1.** How could deep learning methods improve performance on this task?\n",
    "- **10.2.** What additional preprocessing or feature engineering might help classical models?\n",
    "- **10.3.** How can explainable AI techniques make image-based predictions more trustworthy for clinicians?\n",
    "- **10.4.** What are the challenges of scaling this approach to larger, more complex medical image datasets?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fff0b57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be416c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f0727",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- [Breast Histopathology Images (IDC)](https://www.kaggle.com/paultimothymooney/breast-histopathology-images)\n",
    "\n",
    "### Articles\n",
    "\n",
    "- **Machine Learning Methods for Histopathological Image Analysis**\n",
    "<br>*Computational and Structural Biotechnology Journal*\n",
    "  - https://www.csbj.org/article/S2001-0370(17)30086-7/fulltext\n",
    "\n",
    "- **Machine learning methods for histopathological image analysis: Updates in 2024**\n",
    "<br>*Computational and Structural Biotechnology Journal*\n",
    "  - https://www.csbj.org/article/S2001-0370(24)00454-9/fulltext\n",
    "\n",
    "- **A survey on artificial intelligence in histopathology image analysis**\n",
    "<br>*WIREs Data Mining and Knowledge Discovery*\n",
    "  - https://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.1474\n",
    "\n",
    "- **Conventional Machine Learning versus Deep Learning for Magnification Dependent Histopathological Breast Cancer Image Classification: A Comparative Study with Visual Explanation**\n",
    "<br>*Diagnostics (Basel)*\n",
    "  - https://pmc.ncbi.nlm.nih.gov/articles/PMC8001768/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb59f47",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
