{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30bef7e",
   "metadata": {},
   "source": [
    "# AI4Health - 01 - Tabular Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb4390",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e738f74",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Tabular data—structured information organised in rows and columns—is the foundation of most clinical records and healthcare analytics. From electronic health records to laboratory results, much of the data used in medical decision-making is tabular in nature. Machine learning models that can interpret and classify this data have the potential to support clinicians in diagnosing diseases, identifying at-risk patients, and improving outcomes.\n",
    "\n",
    "In this notebook, you will build a machine learning classifier to predict diabetes using the well-known **Pima Indians dataset**. Diabetes is a chronic condition with significant health impacts, and early detection is crucial for effective management. The dataset is a real-world scenario where routine health measurements are used to assess a patient's risk. We use the Pima Indians dataset because the Pima Indian population was known to be highly affected by diabetes, making it a valuable resource for studying risk factors and prediction in a real clinical context.\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "- Explore and visualise clinical tabular data\n",
    "- Prepare data for modelling, including handling class imbalance\n",
    "- Train and evaluate two common classifiers: **Logistic Regression & Decision Trees**\n",
    "- Interpret model performance using **Confusion Matrices** and **ROC Curves**\n",
    "- Reflect on the practical and ethical implications of deploying such models in healthcare\n",
    "\n",
    "By the end of this notebook, you will have hands-on experience with the end-to-end workflow of building a clinical prediction model, and a deeper understanding of both the opportunities and challenges of applying machine learning in medicine.\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "- Understand binary classification and model evaluation in healthcare\n",
    "- Learn how to train logistic regression and decision tree models\n",
    "- Interpret model performance using ROC curves and confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3aa4e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce317",
   "metadata": {},
   "source": [
    "## Additional Context\n",
    "\n",
    "### What is Tabular Clinical Data?\n",
    "\n",
    "Tabular data is the most common format for clinical information. Each row typically represents a patient or a clinical encounter, and each column is a variable such as age, blood pressure, lab results, or diagnosis codes. This structure makes it easy to store, query, and analyse patient data using spreadsheets or databases.\n",
    "\n",
    "In healthcare, tabular datasets are used for:\n",
    "- **Risk prediction** (e.g., likelihood of diabetes, heart disease)\n",
    "- **Resource planning** (e.g., predicting hospital admissions)\n",
    "- **Quality improvement** (e.g., identifying gaps in care)\n",
    "\n",
    "### Why Binary Classification?\n",
    "\n",
    "Many clinical questions are naturally framed as binary classification problems:\n",
    "- Does this patient have diabetes? (Yes/No)\n",
    "- Will this patient be readmitted within 30 days? (Yes/No)\n",
    "- Is this test result abnormal? (Yes/No)\n",
    "\n",
    "Binary classifiers help automate decision support, triage, and screening, but their predictions must be interpreted carefully, especially when errors can have real-world consequences.\n",
    "\n",
    "### Key Concepts in Clinical Machine Learning\n",
    "\n",
    "Understanding the foundational concepts of clinical machine learning is essential before building predictive models. In clinical settings, the data and the way we evaluate models have unique characteristics and implications. Below are some of the most important concepts to grasp:\n",
    "\n",
    "- **Features**: Patient measurements (e.g., glucose, BMI, age)\n",
    "- **Target**: The outcome to predict (e.g., diabetes diagnosis)\n",
    "- **Class Imbalance**: Often, one outcome (e.g., \"no disease\") is much more common than the other. This can bias models if not addressed.\n",
    "- **Model Evaluation**: Metrics like accuracy, precision, recall, and ROC-AUC help assess how well a model performs, but their clinical meaning depends on the context.\n",
    "\n",
    "### Why Use Logistic Regression and Decision Trees?\n",
    "\n",
    "Choosing the right machine learning model is crucial in healthcare, where interpretability and transparency are often as important as predictive accuracy. Two commonly used models in clinical prediction are logistic regression and decision trees, each with their own strengths:\n",
    "\n",
    "- **Logistic Regression**: Simple, interpretable, and widely used for clinical risk prediction. Coefficients can be linked to odds ratios, making them familiar to clinicians.\n",
    "- **Decision Trees**: Provide clear, rule-based decisions that can be visualised and explained, which is valuable for transparency in healthcare.\n",
    "\n",
    "### Clinical Impact and Caution\n",
    "\n",
    "Machine learning can support, but not replace, clinical judgment. Models must be validated, monitored, and used alongside other information. Ethical considerations include fairness, transparency, and the risk of automation bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d83fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69ddc8",
   "metadata": {},
   "source": [
    "## Related Guides\n",
    "\n",
    "- *MatPlotLib - Pyplot:* https://matplotlib.org/stable/tutorials/pyplot.html\n",
    "- *Pandas - DataFrame:* https://pandas.pydata.org/docs/user_guide/dsintro.html#basics-dataframe\n",
    "- *SciKit-Learn - Classification Report:* https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report\n",
    "- *SciKit-Learn - Confusion Matrix:* https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "- *SciKit-Learn - Cross Validation (train, test, split):* https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "- *SciKit-Learn - Decision Tree:* https://scikit-learn.org/stable/modules/tree.html\n",
    "- *SciKit-Learn - Logistic Regression:* https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "- *SciKit-Learn - ROC Curve:* https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f4133",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca39553",
   "metadata": {},
   "source": [
    "## Step 1: Load Required Libraries\n",
    "\n",
    "Before we begin, let's import the essential Python libraries for data analysis, visualisation, and machine learning.\n",
    "\n",
    "- **pandas**: for data manipulation and analysis\n",
    "- **matplotlib** and **seaborn**: for creating informative plots\n",
    "- **scikit-learn**: for splitting data, building models, and evaluating performance\n",
    "\n",
    "Understanding the purpose of each library will help you build, visualise, and evaluate your models effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensure plots show inline in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca90ad",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **1.1.** What is the purpose of `train_test_split`?\n",
    "- **1.2.** Why might we use `roc_curve` and `auc` in a clinical context?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2439416",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dedf8c4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af7291",
   "metadata": {},
   "source": [
    "## Step 2: Load the Dataset\n",
    "\n",
    "Now, we will load the Pima Indians diabetes dataset from a local CSV file. This dataset contains clinical measurements used to predict diabetes.\n",
    "It is important to handle potential errors during loading, such as missing files or corrupted data, especially in healthcare where data integrity is critical.\n",
    "\n",
    "After loading, always verify that the data looks as expected before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14656c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./datasets/pima_indians_diabetes.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"OK\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load dataset:\", e)\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49cd3b",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **2.1.** What might go wrong when loading a dataset from a local file?\n",
    "- **2.2.** Why is it important to handle exceptions when reading files?\n",
    "- **2.3.** How can you verify that the dataset was loaded correctly and contains the expected data?\n",
    "- **2.4.** Why is it important to ensure the dataset has not been tampered with or corrupted, especially in a clinical setting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7239642",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b028c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ac88d",
   "metadata": {},
   "source": [
    "## Step 3: Explore the Data\n",
    "\n",
    "Before modelling, it is crucial to understand the dataset's structure and contents.\n",
    "We will look at the first few rows, summary statistics, and check for missing values.\n",
    "This helps us spot potential issues, such as implausible values (e.g., zero blood pressure), and understand what each feature represents clinically.\n",
    "\n",
    "Reflect on how data quality and feature meaning can impact downstream analysis and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52126fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1565a",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **3.1.** Why is it important to know the structure of your dataset before starting analysis?\n",
    "- **3.2.** What do the columns represent clinically?\n",
    "- **3.3.** Are there any features with unusual min/max values?\n",
    "- **3.4.** How might you handle features with implausible values (e.g., zero for blood pressure)?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68c0358b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6fdd05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fef1f",
   "metadata": {},
   "source": [
    "## Step 4: Visualise Class Distribution\n",
    "\n",
    "Let's examine the distribution of the target variable—whether patients are diabetic or not.\n",
    "Visualising class balance is important because imbalanced datasets can bias models and affect their ability to generalise.\n",
    "\n",
    "Consider how class imbalance might influence your model's predictions and what strategies you could use to address it.\n",
    "\n",
    "- *Seaborn - countplot:* https://seaborn.pydata.org/generated/seaborn.countplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Outcome', data=df)\n",
    "plt.title(\"Diabetes Diagnosis Distribution (0 = No, 1 = Yes)\")\n",
    "plt.xlabel(\"Outcome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c93850",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **4.1.** Are the classes balanced?\n",
    "- **4.2.** What could be the impact of imbalance on model training?\n",
    "- **4.3.** What techniques can you use to address class imbalance in your dataset?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd20bda4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2419409e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975515c",
   "metadata": {},
   "source": [
    "## Step 5: Split the Data\n",
    "\n",
    "To fairly evaluate our models, we will split the data into training and testing sets.\n",
    "We use stratified sampling to ensure the class proportions remain consistent in both sets, which is especially important for imbalanced data.\n",
    "\n",
    "Think about why this split is necessary and how improper splitting could lead to misleading results.\n",
    "\n",
    "- *SciKit-Learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis=1)  # Features\n",
    "y = df['Outcome']               # Target label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbc97c",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **5.1.** Why do we split data into training and testing sets?\n",
    "- **5.2.** What is the role of `stratify=y`?\n",
    "- **5.3.** What could happen if you do not stratify by the target variable when splitting the data?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3bd567b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1bd1b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e75610",
   "metadata": {},
   "source": [
    "## Step 6: Train Logistic Regression\n",
    "\n",
    "We will train a logistic regression model to predict diabetes.\n",
    "Logistic regression estimates the probability of an outcome using a linear combination of features.\n",
    "After training, we will evaluate its performance using metrics like precision, recall, and F1-score.\n",
    "\n",
    "Consider how these metrics relate to clinical decision-making and what the model's coefficients might reveal about risk factors.\n",
    "\n",
    "- *SciKit-Learn - classification_report:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "- *SciKit-Learn - LogisticRegression:* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Logistic Regression ---\")\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase iterations to ensure convergence\n",
    "lr.fit(X_train, y_train)                # Train the model\n",
    "y_pred_lr = lr.predict(X_test)          # Predict on test set\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39e219",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **6.1.** How does logistic regression estimate the likelihood of diabetes?\n",
    "- **6.2.** What performance metrics are most relevant here?\n",
    "- **6.3.** How can you interpret the coefficients of a logistic regression model in a clinical context?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7f3b0c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9295db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90d414",
   "metadata": {},
   "source": [
    "## Step 7: Train Decision Tree\n",
    "\n",
    "Next, we will train a decision tree classifier.\n",
    "Decision trees make predictions by splitting data based on feature thresholds.\n",
    "We will limit the tree's depth to prevent overfitting and improve interpretability.\n",
    "\n",
    "Compare the strengths and weaknesses of decision trees and logistic regression, especially in terms of transparency and clinical usefulness.\n",
    "\n",
    "- *SciKit-Learn - classification_report:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "- *SciKit-Learn - DecisionTreeClassifier:* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Decision Tree ---\")\n",
    "dt = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2413f",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **7.1.** What does `max_depth=4` mean in terms of model complexity?\n",
    "- **7.2.** What are the pros and cons of decision trees compared to logistic regression?\n",
    "- **7.3.** How might the interpretability of a decision tree benefit clinicians?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a111ff02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ce5eb72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08b600",
   "metadata": {},
   "source": [
    "## Step 8: Confusion Matrix Comparison\n",
    "\n",
    "Let's compare the confusion matrices for both models.\n",
    "The confusion matrix shows how many predictions were correct or incorrect, broken down by class.\n",
    "This helps us understand the types of errors each model makes—such as false positives and false negatives—and their potential clinical consequences.\n",
    "\n",
    "Reflect on which errors are more critical in a healthcare context and how you might adjust your model to minimise them.\n",
    "\n",
    "- *SciKit-Learn - confusion_matrix:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "- *Seaborn - heatmap:* https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "for ax, y_pred, title in zip(axes, [y_pred_lr, y_pred_dt], ['Logistic Regression', 'Decision Tree']):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix: {title}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ede2fd",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **8.1.** Which model makes more false positives or false negatives?\n",
    "- **8.2.** What would be the consequence of each in a clinical context?\n",
    "- **8.3.** How could you adjust your model or threshold to prioritise reducing false negatives?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4aa76ce0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc64cda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2299d9",
   "metadata": {},
   "source": [
    "## Step 9: ROC Curves\n",
    "\n",
    "We will plot ROC (Receiver Operating Characteristic) curves to visualise the trade-off between sensitivity (true positive rate) and specificity (false positive rate) at different thresholds.\n",
    "The AUC (Area Under the Curve) summarises the model's ability to distinguish between classes.\n",
    "\n",
    "Think about what a good AUC means in practice, how you would select a threshold for clinical use, and what factors might influence that choice.\n",
    "\n",
    "- *SciKit-Learn - roc_curve:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "- *SciKit-Learn - auc:* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(model, model_name):\n",
    "    \"\"\"Plot ROC curve for a given model.\"\"\"\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_roc(lr, \"Logistic Regression\")\n",
    "plot_roc(dt, \"Decision Tree\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bd7f2",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- **9.1.** What does an AUC of 0.79 and 0.82 mean in a clinical context?\n",
    "- **9.2.** Are both models better than chance?\n",
    "- **9.3.** Are both models good enough to use in a clinic?\n",
    "- **9.4.** How would you choose an appropriate threshold for clinical use, and what factors would influence your decision?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec1683dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb80f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a165537",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Reflection\n",
    "\n",
    "In this notebook, we walked through the complete workflow of building a machine learning classifier for a real-world healthcare problem—predicting diabetes from clinical tabular data. We started by loading and exploring the Pima Indians diabetes dataset, visualising the distribution of the target classes, and discussing the importance of class balance. We then prepared the data by splitting it into training and testing sets, ensuring the class proportions were preserved.\n",
    "\n",
    "Next, we trained two different models: logistic regression and a decision tree, and evaluated their performance using classification reports, confusion matrices, and ROC curves. Along the way, we reflected on the clinical meaning of various metrics, the impact of class imbalance, and the practical consequences of model errors. This hands-on process highlighted both the power and the limitations of machine learning in a clinical context, emphasising the need for careful evaluation and interpretation before deploying such models in practice.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- We trained two models: Logistic Regression & Decision Tree.\n",
    "- Both models show moderate predictive ability on the diabetes dataset.\n",
    "- ROC and confusion matrices help interpret real-world consequences of predictions.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "- **10.1.** What additional clinical variables could improve prediction (e.g., family history, lab tests)?\n",
    "- **10.2.** How could such a model be integrated into real clinical workflows?\n",
    "- **10.3.** What safeguards are needed to handle incorrect predictions?\n",
    "- **10.4.** How would you monitor and update the model to ensure ongoing accuracy and fairness?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed29ac5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ecf25f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8375d",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- **Pima Indians Diabetes Database**\n",
    "  - https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "### Articles\n",
    "\n",
    "- **Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus**\n",
    "<br>*Proceedings of the Annual Symposium on Computer Application in Medical Care*\n",
    "  - https://pmc.ncbi.nlm.nih.gov/articles/PMC2245318/\n",
    "\n",
    "- **Machine Learning in Medicine**\n",
    "<br>*New England Journal of Medicine*\n",
    "  - https://www.nejm.org/doi/full/10.1056/NEJMra1814259\n",
    "\n",
    "- **Predictive models for diabetes mellitus using machine learning techniques**\n",
    "<br>*BMC Endocrine Disorders*\n",
    "  - https://bmcendocrdisord.biomedcentral.com/articles/10.1186/s12902-019-0436-6\n",
    "\n",
    "- **Interpretable machine learning method to predict the risk of pre-diabetes using a national-wide cross-sectional data: evidence from CHNS**\n",
    "<br>*BMC Public Health*\n",
    "  - https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-025-22419-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bff78b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
