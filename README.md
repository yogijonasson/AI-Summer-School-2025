### Topics Covered

- **Introduction to causality and causal reasoning** â€“ Hisham  
- **Machine & Deep Learning** â€“ Clement  
- **AI & Intellectual Property** â€“ *(TBD)*  
- **AI in Health** â€“ Clement  
- **Frugal AI: Social & Environmental Impact** â€“ Yogi
-  **AI Project Management & Data Challenge** â€“ Yogi  
- **Generative AI** â€“ Hisham  

### Introduction to causality and causal reasoning

This section covers foundations of causal graphs, probabilistic models, and causal discovery.  While correlation identifies associations between variables, causal inference seeks to answer what happens if we intervene? This shift from observation to intervention is critical in fields like medicine, economics, and artificial intelligence.

#### ðŸ” Key Concepts Covered
##### 1. Causality vs. Correlation
- Describes the limitations of associational statistics.
- Demonstrates how correlation does not imply causation using simple examples.

##### 2. Counterfactual Reasoning
- Introduces the concept of counterfactuals, i.e., reasoning about "what would have happened ifâ€¦"
- Provides formal notation for counterfactual queries and their use in causal reasoning.

##### 3. Structural Causal Models (SCMs)
- Formal framework proposed by Judea Pearl.
- Defines variables and relationships via directed acyclic graphs (DAGs).
- Encodes assumptions explicitly to model interventions and counterfactuals.

##### 4. Do-Calculus and Interventions
- Introduces the do-operator $do(X = x)$ to model interventions.
- Explains how to compute post-intervention distributions.


##### 5. Identifiability and Estimation
- Discusses when a causal quantity is identifiable from observational data.
- Introduces conditions like back-door and front-door criteria.

### Frugal AI: Social & Environmental Impact

Frugal AI refers to resource-efficient, socially equitable, and environmentally sustainable approaches to AI development and deployment.

#### ðŸš© Key Challenges Addressed
- High carbon footprint from large-scale AI models (e.g., LLMs)
- Social exclusion in under-resourced regions
- Misalignment between AI development and global sustainability goals

#### ðŸ“š Related Theories and Readings
- **Donella Meadows â€“ *Leverage Points***  
  - Frugal AI targets deep leverage points (e.g., shifting system goals and mindsets) to move beyond performance-focused AI.
- **Steve Easterbrook â€“ *From Computational Thinking to Systems Thinking***  
  - Encourages viewing AI as part of complex socio-technical systems requiring holistic, interdisciplinary approaches.
- **Red AI vs. Green AI**  
  - *Red AI*: Prioritizes performance, scale, and accuracyâ€”often ignoring energy and resource costs.  
  - *Green AI*: Focuses on efficiency, transparency, and sustainabilityâ€”core to the Frugal AI approach.

#### ðŸ§­ Core Principles
- âš¡ **Environmental Efficiency**
  - Model compression, pruning, and use of edge computing
  - Energy-efficient training and deployment processes

- ðŸŒ **Social Inclusion**
  - Design AI for low-resource environments and infrastructure
  - Utilize transfer learning, federated learning, and inclusive datasets

- ðŸ§  **Systems Thinking**
  - Evaluate AI through full life cycle assessment (LCA)
  - Consider unintended consequences and feedback loops

- ðŸŽ¯ **Ethical & Sustainable Governance**
  - Align AI development with the UN Sustainable Development Goals (SDGs)
  - Encourage transparency, accountability, and interdisciplinary collaboration

#### ðŸŽ¯ Overall Goal
> To move toward AI systems that **do more with less**, embedding sustainability, equity, and ethical responsibility as foundationalâ€”not optionalâ€”values in innovation.


### ðŸ§© AI Project Management & Use Case Design (Data Challenge)

As part of the challenge, we were tasked with **managing and delivering an end-to-end AI project** in under one day. The goal was to apply both theoretical and practical AI project management principles to a realistic industrial use case.

---

#### ðŸ”„ AI Project Management Phases (Applied in Our Challenge)

1. **Business Understanding**  
   Defined the industrial need: automatic quotation of product manufacturing costs.

2. **Data Understanding**  
   Explored the provided dataset, identified gaps, and assessed quality and relevance.

3. **Data Preparation**  
   Cleaned, processed, and structured the data for modeling.

4. **Modeling**  
   Applied machine learning algorithms (Linear Regression, Random Forest) to predict prices.

5. **Evaluation**  
   Attempted to assess model performance based on accuracy and business relevance.

6. **Deployment Planning**  
   Proposed a basic integration plan into an industrial workflow.

7. **Monitoring & Maintenance (Theoretical)**  
   Considered how the model would need to evolve over time.

---

#### ðŸ› ï¸ Use Case: Automatic Product Quotation System

- Designed an AI-powered tool to support **cost estimation** in a manufacturing context.
- Mapped industrial needs to data and technical requirements.
- Balanced trade-offs between **accuracy**, **interpretability**, and **feasibility**.
- Shared insights and solution architecture in a final **team presentation**.

---

#### ðŸ’¡ Key Takeaways from the Data Challenge

- We had only **5 hours** to regroup and complete the challenge, which tested our ability to prioritize, collaborate, and make quick decisions.
- We completed most of the presentationâ€”including project planning and system designâ€”but couldnâ€™t deliver a **functioning machine learning model** in time.
- Despite trying both **Linear Regression** and **Random Forest**, our models failed to produce reliable predictions.
- Possible reasons include:
  - Data cleaning issues
  - Bugs or missteps in our **Python implementation**
  - Misalignment between model selection and the data characteristics
- This made it clear that early alignment around **data quality and preprocessing** is critical.
- Our biggest takeaway: **if the model fails, revisit the data pipeline first**â€”debugging at the model stage without clean data is often wasted effort.
- Moving forward, we need to rebuild the pipeline with a stronger foundation in **data cleaning**, **model debugging**, and **performance evaluation**.

ðŸ“‚ These are our
[team presentation slides](AI%20Project%20Management%20%26%20Data%20Challanges/AI-Driven%20Cost%20Estimation%20for%20Injection%20Mold%20Quotation.pdf) and 
[workbook/code](AI%20Project%20Management%20%26%20Data%20Challanges/Data_Project_Team_3%20Final.ipynb) from the data challange.


### Generative AI

This section covers fundamental theories of semantic representation in Natural Language Processing (NLP)

#### ðŸ” Key Concepts Covered
##### 1. Ontology of Meaning
Semantic meaning is formally defined as the invariant truth conditions shared across paraphrased expressions, exemplified by deriving "Socrates is mortal" from "All men are mortal." This conceptual framework is implemented computationally through three complementary paradigms: symbolic logic using first-order predicate calculus (e.g., $\forall x: { } human(x) \Rightarrow mortal(x) $); vector geometry that maps words to $\mathbb{R}^D$ where angular distance quantifies semantic similarity $(e.g.,~\arccos\left( \frac{\vec{v}_1 \cdot \vec{v}_2}{\lVert \vec{v}_1 \rVert \lVert \vec{v}_2 \rVert} \right))$  reveals "anteater" ($\vec{v}_1$) and "ant" ($\vec{v}_2$) are 15Â° apart); and neural networks that learn continuous representations $\phi: \mathcal{V} \rightarrow \mathbb{R}^D$ directly from linguistic data, prioritizing scalability over interpretability.

##### 2. Componential Semantics
Lexical meaning is decomposed into atomic primitivesâ€”binary features ($man = [+male, +adult]$) for basic terms or continuous activations across 873 Larousse concepts for richer vocabulary (e.g., "peace" activates $PEACE=0.9$, $LIBERTY=0.8$). Semantic composition is governed by algebraic operations: normalized summation $\left( v_a\mathbin{\oplus_b} = \frac{v_a + v_b}{\lVert v_a + v_b \rVert} \right) $) merges primitives, term-wise product ($v_a\mathbin{\otimes_b} = v_a \odot v_b $) extracts intersections, and weak contextualization ($\gamma(v_a, v_b) = v_a + v_b + \left( v_a \odot v_b \right) $) enriches meaning. Polysemy is resolved via vector superposition, as in $bat = 0.6\cdot v_{animal} + 0.4 \cdot v_{sports{ }tool}$.

##### 3. Distributional Semantics"You understand a word by the words around it":

- Basic Approach:

  - Each word gets a unique ID (like "apple=ID73")

  - Documents become lists of these IDs


- Advanced Approach (Word2Vec):

  - Predicts neighboring words (e.g., "juice" likely near "orange")

  - Discovers relationships: king - man + woman â‰ˆ queen

  - Groups similar words (Sweden/Norway/Denmark cluster together)

##### Evolutionary Synthesis
The trajectory progresses from interpretable handcrafted features (1960s-2000s) to data-driven statistical embeddings (2010s), culminating in hybrid deep learning models that balance precision and scalability. This convergence establishes vectors as the universal substrate for semantic computation in modern NLP systems.

### âš–ï¸ AI & Intellectual Property

- **Human authorship is required** for most IP rights (copyrights, patents).
- **AI-generated content** (text, images, inventions) typically cannot be patented or copyrighted on its own.
- **Prompts** used to guide AI (e.g. in Midjourney or ChatGPT) are **not considered inventions** and don't qualify for patent protection.

#### ðŸŽ¨ Notable Example
- In 2022, an AI-generated image ("**ThÃ©Ã¢tre D'opÃ©ra Spatial**") won an art competition using **Midjourney**.
- It sparked controversy over fairness, originality, and copyrightâ€”raising global debate on AI's role in creative fields.

#### ðŸ”‘ Takeaways
- Patents and copyrights currently **exclude non-human creators**.
- Legal frameworks are **not yet adapted** to fully address AI-generated works.
- Future laws may evolve to recognize **human-AI collaboration**, but the field remains a legal gray zone.

### ðŸ§¬ AI in Health

AI technologies are revolutionizing medicine through **precision-based treatments**, enabled by **big data**, **clinical insights**, and **multi-omics analysis**. This section combines theoretical concepts with hands-on Python notebooks developed as part of our AI in Health module.

---

#### ðŸ§  Key Concepts

- **Precision Medicine**  
  AI enables analysis of large-scale biomedical data to design **targeted, personalized treatments** based on demographic and molecular information.

- **Targeted Therapies**  
  Modern anti-cancer drugs are designed to interact with specific **molecular targets**, often proteins, identified through data-driven AI methods.

- **Disease Understanding**  
  - A disease involves cellular or tissue-level dysfunction that impairs organ performance and causes clinical symptoms.  
  - **Chronic diseases** last 3+ months and often require longitudinal data for proper analysis.

- **Global Health Impact**  
  AI helps **characterize patients at scale** and propose targeted interventions across populations.

- **The Multi-Omics Era**  
  Diseases arise from complex interactions across different biological layersâ€”**genomics, proteomics, transcriptomics**, etc.â€”which AI helps interpret through integrated models.

---

#### ðŸ“š AI for Health â€“ Python Notebooks

1. **ðŸ§¾ Tabular Data: Risk Classification**  
   [`AI4Health_01_Tabular_Classification.ipynb`](AI%20For%20Health/AI4Health_01_Tabular_Classification.ipynb)  
   - Applies AI to structured patient data for **disease risk prediction**.
   - Demonstrates classification pipelines with demographic and clinical features.

2. **ðŸ“„ Clinical Text Classification**  
   [`AI4Health_02_Clinical_Text_Classification.ipynb`](AI%20For%20Health/AI4Health_02_Clinical_Text_Classification.ipynb)  
   - Processes real-world **clinical notes** using NLP techniques.
   - Builds models to **classify health conditions** from unstructured text data.

3. **ðŸ§¬ Multi-Omics Precision Modeling**  
   [`AI4Health_03_Omics_Precision_Medicine.ipynb`](AI%20For%20Health/AI4Health_03_Omics_Precision_Medicine.ipynb)  
   - Integrates genomic and molecular-level data.
   - Demonstrates how AI can support **precision medicine** by linking genetic profiles to treatment outcomes.

4. **ðŸ§« Histology Image Classification**  
   [`AI4Health_04_Histology_Image_Classification.ipynb`](AI%20For%20Health/AI4Health_04_Histology_Image_Classification.ipynb)  
   - Uses computer vision to analyze **microscopic tissue images**.
   - Helps automate disease diagnosis and improve early detection.

---

#### ðŸ”‘ Summary

These notebooks demonstrate how AI can be applied across multiple healthcare data typesâ€”structured tables, clinical text, omics, and imagesâ€”to support precision medicine and improve patient care.

> ðŸ’¡ Together, they reflect how AI is **not just a tool**, but a transformative force for global health and next-generation medical practices.
